#!/usr/bin/env python3
"""
ü§ñ Pipeline Daemon - Automatizaci√≥n completa del proceso
Ejecuta el pipeline completo de forma autom√°tica
"""

import time
import schedule
import logging
from datetime import datetime
import sys
import os

# A√±adir el directorio src al path
sys.path.append('src')

from pipeline.db import PipelineDB

class PipelineDaemon:
    def __init__(self):
        self.db = PipelineDB()
        
        # Configurar logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/daemon.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def run_discovery(self):
        """Ejecutar descubrimiento de nuevos videos"""
        try:
            self.logger.info("üîç Iniciando descubrimiento de videos...")
            # Por ahora, solo simulamos el descubrimiento
            # En una implementaci√≥n completa, aqu√≠ ir√≠a la integraci√≥n con YouTube API
            discovered = []  # self.discoverer.discover_new_videos()
            self.logger.info(f"‚úÖ Descubiertos {len(discovered)} videos nuevos")
            return discovered
        except Exception as e:
            self.logger.error(f"‚ùå Error en descubrimiento: {e}")
            return []
    
    def run_download(self):
        """Descargar videos pendientes"""
        try:
            self.logger.info("üì• Iniciando descarga de videos...")
            # Simulaci√≥n de descarga
            downloaded = 0
            self.logger.info(f"‚úÖ Descargados {downloaded} videos")
            return downloaded
        except Exception as e:
            self.logger.error(f"‚ùå Error en descarga: {e}")
            return 0
    
    def run_transcription(self):
        """Transcribir videos descargados"""
        try:
            self.logger.info("üé§ Iniciando transcripci√≥n...")
            # Simulaci√≥n de transcripci√≥n
            transcribed = 0
            self.logger.info(f"‚úÖ Transcritos {transcribed} videos")
            return transcribed
        except Exception as e:
            self.logger.error(f"‚ùå Error en transcripci√≥n: {e}")
            return 0
    
    def run_segmentation(self):
        """Segmentar transcripciones en clips"""
        try:
            self.logger.info("‚úÇÔ∏è Iniciando segmentaci√≥n...")
            # Simulaci√≥n de segmentaci√≥n
            segmented = 0
            self.logger.info(f"‚úÖ Creados {segmented} segmentos")
            return segmented
        except Exception as e:
            self.logger.error(f"‚ùå Error en segmentaci√≥n: {e}")
            return 0
    
    def run_composition(self):
        """Componer shorts finales"""
        try:
            self.logger.info("üé¨ Iniciando composici√≥n...")
            # Simulaci√≥n de composici√≥n
            composed = 0
            self.logger.info(f"‚úÖ Compuestos {composed} shorts")
            return composed
        except Exception as e:
            self.logger.error(f"‚ùå Error en composici√≥n: {e}")
            return 0
    
    def run_auto_approval(self):
        """Aprobar autom√°ticamente shorts con score alto"""
        try:
            self.logger.info("ü§ñ Revisando shorts para aprobaci√≥n autom√°tica...")
            # Simulaci√≥n de aprobaci√≥n autom√°tica
            auto_approved = 0
            if auto_approved > 0:
                self.logger.info(f"‚úÖ Auto-aprobados {auto_approved} shorts")
            return auto_approved
        except Exception as e:
            self.logger.error(f"‚ùå Error en aprobaci√≥n autom√°tica: {e}")
            return 0
    
    def run_publishing(self):
        """Publicar shorts aprobados"""
        try:
            if not os.getenv('AUTO_PUBLISH_ENABLED', 'false').lower() == 'true':
                return 0
                
            self.logger.info("üì§ Iniciando publicaci√≥n...")
            # Simulaci√≥n de publicaci√≥n
            published = 0
            self.logger.info(f"‚úÖ Publicados {published} shorts")
            return published
        except Exception as e:
            self.logger.error(f"‚ùå Error en publicaci√≥n: {e}")
            return 0
    
    def run_full_pipeline(self):
        """Ejecutar el pipeline completo"""
        self.logger.info("üöÄ Iniciando ejecuci√≥n completa del pipeline")
        start_time = datetime.now()
        
        # Verificar si el daemon est√° pausado
        if self.db.is_daemon_paused():
            self.logger.info("‚è∏Ô∏è Daemon pausado, saltando ejecuci√≥n")
            return
        
        stats = {
            'discovered': self.run_discovery(),
            'downloaded': self.run_download(),
            'transcribed': self.run_transcription(),
            'segmented': self.run_segmentation(),
            'composed': self.run_composition(),
            'auto_approved': self.run_auto_approval(),
            'published': self.run_publishing()
        }
        
        duration = datetime.now() - start_time
        self.logger.info(f"‚úÖ Pipeline completado en {duration}")
        self.logger.info(f"üìä Estad√≠sticas: {stats}")
        
        # Guardar estad√≠sticas en la base de datos si el m√©todo existe
        try:
            self.db.save_pipeline_run_stats(stats, duration.total_seconds())
        except AttributeError:
            # El m√©todo no existe a√∫n, solo logueamos
            self.logger.info("üìù M√©todo save_pipeline_run_stats no implementado a√∫n")
    
    def start(self):
        """Iniciar el daemon con programaci√≥n"""
        self.logger.info("ü§ñ Iniciando Pipeline Daemon")
        
        # Programar tareas
        schedule.every(30).minutes.do(self.run_full_pipeline)
        schedule.every().hour.at(":00").do(self.run_discovery)
        schedule.every(2).hours.do(self.run_auto_approval)
        
        # Ejecutar una vez al inicio
        self.run_full_pipeline()
        
        self.logger.info("‚è∞ Daemon iniciado, esperando pr√≥xima ejecuci√≥n...")
        
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # Revisar cada minuto
        except KeyboardInterrupt:
            self.logger.info("üõë Deteniendo daemon...")
        except Exception as e:
            self.logger.error(f"‚ùå Error en daemon: {e}")
            raise

if __name__ == "__main__":
    daemon = PipelineDaemon()
    daemon.start()
