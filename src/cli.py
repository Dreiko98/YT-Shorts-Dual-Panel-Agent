#!/usr/bin/env python3
"""
CLI principal para el pipeline de YT Shorts Dual-Panel Agent.
"""

import sys
from pathlib import Path
from typing import Optional

import typer
from rich import print as rprint
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress
from typing_extensions import Annotated

# A√±adir src/ al path para imports
sys.path.insert(0, str(Path(__file__).parent))

# Cargar variables de entorno desde .env si existe
try:
    from dotenv import load_dotenv
    _env_path = Path('.env')
    if _env_path.exists():
        load_dotenv(dotenv_path=_env_path, override=False)
except Exception:
    pass

app = typer.Typer(
    name="yts",
    help="üé¨ YT Shorts Dual-Panel Agent - Pipeline automatizado para generar YouTube Shorts",
    rich_markup_mode="rich",
)
console = Console()


@app.command()
def pipeline(
    podcast_video: str = typer.Argument(..., help="Video base del podcast (vertical o recortable)"),
    broll_video: str = typer.Argument(..., help="Video b-roll para panel inferior"),
    workdir: str = typer.Option("data", help="Directorio ra√≠z de trabajo"),
    model: str = typer.Option("base", help="Modelo Whisper"),
    language: str = typer.Option(None, help="Forzar idioma"),
    max_clips: int = typer.Option(3, help="M√°x shorts a generar"),
    fast_subs: bool = typer.Option(True, help="Activar subt√≠tulos r√°pidos"),
    words_target: int = typer.Option(2, help="Palabras por subt√≠tulo en modo r√°pido"),
    min_sub: float = typer.Option(0.30, help="Duraci√≥n m√≠nima subt√≠tulo"),
    max_sub: float = typer.Option(0.90, help="Duraci√≥n m√°xima subt√≠tulo"),
    decorated: bool = typer.Option(True, help="Ciclar colores y halo animado"),
):
    """Pipeline completa: transcribir -> segmentar IA -> componer shorts.
    Requiere: ffmpeg, whisper instalado y API OpenAI configurada para segmentaci√≥n IA.
    """
    import os, json
    from pathlib import Path
    from .pipeline.transcribe import transcribe_video_file, check_whisper_requirements
    from .pipeline.ai_segmenter import AITranscriptSegmenter, AISegmentationConfig
    from .pipeline.editor import compose_short_from_files
    
    base = Path(workdir)
    transcripts_dir = base / 'transcripts'
    segments_dir = base / 'segments'
    shorts_dir = base / 'shorts'
    for d in (transcripts_dir, segments_dir, shorts_dir):
        d.mkdir(parents=True, exist_ok=True)

    podcast_path = Path(podcast_video)
    broll_path = Path(broll_video)
    if not podcast_path.exists() or not broll_path.exists():
        rprint("[red]‚ùå Archivos de entrada no encontrados[/red]")
        raise typer.Exit(1)

    # Cache de transcripci√≥n (usa hash simple por tama√±o+mtime)
    transcript_json = transcripts_dir / f"{podcast_path.stem}_transcript.json"
    if transcript_json.exists():
        rprint(f"[cyan]üóÉÔ∏è  Usando transcripci√≥n cacheada:[/cyan] {transcript_json}")
    else:
        rprint("[cyan]üé§ Transcribiendo...[/cyan]")
        req = check_whisper_requirements()
        if not req['whisper_installed'] or not req['torch_available']:
            rprint("[red]‚ùå Whisper o PyTorch no disponibles[/red]")
            raise typer.Exit(1)
        tr_result = transcribe_video_file(podcast_path, transcripts_dir, model=model, device='auto', language=language)
        if not tr_result.get('success'):
            rprint("[red]‚ùå Fall√≥ transcripci√≥n[/red]"); raise typer.Exit(1)
        transcript_json = Path(tr_result['transcript_json'])
        rprint(f"[green]‚úÖ Transcripci√≥n lista:[/green] {transcript_json}")

    rprint("[magenta]ü§ñ Segmentando con IA...[/magenta]")
    ai_conf = AISegmentationConfig(max_clips=max_clips, min_duration=15, max_duration=59, target_duration=30)
    ai_seg = AITranscriptSegmenter(ai_conf)
    export_path = segments_dir / f"{transcript_json.stem}_candidates.json"
    try:
        candidates = ai_seg.segment_transcript(transcript_json)
        if not candidates:
            raise RuntimeError("IA no devolvi√≥ candidatos")
        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump({"candidates": [c.dict() for c in candidates]}, f, ensure_ascii=False, indent=2)
        rprint(f"[green]‚úÖ Candidatos IA:[/green] {export_path}")
    except Exception as e:
        rprint(f"[yellow]‚ö†Ô∏è  IA fall√≥ ({e}); usando segmentaci√≥n cl√°sica[/yellow]")
        from .pipeline.segmenter import segment_transcript_file
        classic_conf = {
            "min_clip_duration": 15,
            "max_clip_duration": 59,
            "target_clip_duration": 30,
            "overlap_threshold": 0.1,
            "scoring_weights": {"keyword_match":0.3,"sentence_completeness":0.25,"duration_fit":0.25,"speech_quality":0.2},
            "important_keywords": []
        }
        candidates = segment_transcript_file(transcript_path=transcript_json, output_dir=segments_dir, config=classic_conf)
        if not candidates:
            rprint('[red]‚ùå Sin candidatos tras fallback[/red]'); raise typer.Exit(1)
        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump({"candidates": [c.dict() for c in candidates]}, f, ensure_ascii=False, indent=2)
        rprint(f"[green]‚úÖ Candidatos (fallback):[/green] {export_path}")

    if fast_subs:
        os.environ['SHORT_SUB_MODE'] = 'fast'
        os.environ['FAST_WORDS_TARGET'] = str(words_target)
        os.environ['FAST_SUB_MIN'] = str(min_sub)
        os.environ['FAST_SUB_MAX'] = str(max_sub)
        if decorated:
            os.environ['FAST_SUB_COLOR_CYCLE'] = '1'
            os.environ['FAST_SUB_BOUNCE'] = '1'
    
    rprint("[yellow]üé¨ Componiendo shorts...[/yellow]")
    results = compose_short_from_files(podcast_path, broll_path, transcript_json, export_path, shorts_dir, max_shorts=max_clips)
    ok = sum(1 for r in results if r.get('success'))
    rprint(f"[green]‚úÖ Shorts generados:[/green] {ok}/{len(results)}")
    for r in results:
        if r.get('success'):
            rprint(f"  ‚Ä¢ {r['output_path']}")

    # M√©tricas agregadas
    metrics = {
        "total_candidates": len(results),
        "successful": ok,
        "failed": len(results) - ok,
        "avg_duration": round(sum(r.get('duration',0) for r in results if r.get('success'))/ok,2) if ok else 0,
        "total_render_time_est_s": None,
    }
    metrics_path = shorts_dir / 'pipeline_metrics.json'
    with open(metrics_path, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)
    rprint(f"[blue]üìä M√©tricas guardadas:[/blue] {metrics_path}")
    rprint('[bold green]üèÅ Pipeline completa[/bold green]')
@app.command()
def discover(
    config: Path = typer.Option(Path("configs/channels.yaml"), exists=True, help="Ruta a channels.yaml"),
    db_path: Path = typer.Option(Path("data/pipeline.db"), help="Ruta a la base de datos"),
):
    """üîç Descubrir nuevos videos largos candidatos y almacenarlos en la base de datos.

    Usa configs/channels.yaml para definir canales y filtros. Requiere YOUTUBE_API_KEY.
    """
    from .pipeline.db import PipelineDB
    from .pipeline.discovery import discover_new_videos, DiscoveryError

    rprint("[yellow]üîç Ejecutando discovery...[/yellow]")
    db = PipelineDB(str(db_path))
    try:
        new_videos = discover_new_videos(db, config)
    except DiscoveryError as e:
        rprint(f"[red]‚ùå Error discovery: {e}[/red]")
        raise typer.Exit(1)

    if not new_videos:
        rprint("[cyan]‚ÑπÔ∏è  No se encontraron nuevos videos[/cyan]")
    else:
        rprint(f"[green]‚úÖ Nuevos videos: {len(new_videos)}[/green]")
        for v in new_videos:
            rprint(f"  ‚Ä¢ {v['video_id']} | {v['duration_seconds']//60}m | {v['title'][:70]}")


@app.command()
def download(
    limit: Annotated[int, typer.Option("--limit", "-l", help="M√°x videos a descargar")] = 3,
    db_path: Annotated[Path, typer.Option(help="Ruta DB")] = Path("data/pipeline.db"),
    base_dir: Annotated[Path, typer.Option(help="Directorio base datos/raw")]=Path("data"),
    verbose: Annotated[bool, typer.Option("--verbose", "-v", help="Logs debug")]=False,
):
    """‚¨áÔ∏è  Descargar videos pendientes (status=discovered) con yt-dlp."""
    from .pipeline.db import PipelineDB
    from .pipeline.downloader import download_pending
    import logging
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    rprint("[yellow]‚¨áÔ∏è  Descargando videos pendientes...[/yellow]")
    db = PipelineDB(str(db_path))
    results = download_pending(db, limit=limit, base_dir=base_dir)
    if not results:
        rprint("[cyan]‚ÑπÔ∏è  No hay videos pendientes[/cyan]")
        raise typer.Exit()
    ok = sum(1 for r in results if r['success'])
    rprint(f"[green]‚úÖ Descargados correctamente:[/green] {ok}/{len(results)}")
    for r in results:
        if r['success']:
            rprint(f"  ‚Ä¢ {r['video_id']} -> {r['file_path']}")
        else:
            rprint(f"  ‚Ä¢ {r['video_id']} [red]Error:[/red] {r['error']}")


@app.command()
def normalize(
    force: Annotated[bool, typer.Option("--force", "-f", help="Forzar renormalizaci√≥n")] = False,
    target_fps: Annotated[int, typer.Option("--fps", help="FPS objetivo")] = 30,
):
    """üéµ Normalizar audio y video (fps, resoluci√≥n, loudness)."""
    rprint("[yellow]üéµ Normalizando audio/video...[/yellow]")
    
    # TODO: Implementar normalize.py
    rprint(f"[blue]üéØ FPS objetivo:[/blue] {target_fps}")
    rprint(f"[blue]üîÑ Forzar renormalizaci√≥n:[/blue] {force}")
    rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")


@app.command()
def transcribe(
    video_path: str = typer.Argument(..., help="Ruta al archivo de video"),
    output_dir: str = typer.Option("data/transcripts", help="Directorio de salida"),
    model: str = typer.Option("base", help="Modelo Whisper (tiny, base, small, medium, large)"),
    language: str = typer.Option(None, help="Idioma forzado (es, en, etc.)"),
    device: str = typer.Option("auto", help="Dispositivo (auto, cpu, cuda)")
):
    """Transcribir video usando Whisper."""
    from pathlib import Path
    from .pipeline.transcribe import transcribe_video_file, TranscriptionError, check_whisper_requirements
    
    console.print(f"üé§ [bold]Transcribiendo video:[/bold] {video_path}")
    
    # Verificar requirements
    requirements = check_whisper_requirements()
    if not requirements["whisper_installed"]:
        console.print("‚ùå [red]Whisper no est√° instalado. Ejecuta: pip install openai-whisper[/red]")
        raise typer.Exit(1)
    
    if not requirements["torch_available"]:
        console.print("‚ùå [red]PyTorch no est√° disponible[/red]")
        raise typer.Exit(1)
    
    video_file = Path(video_path)
    if not video_file.exists():
        console.print(f"‚ùå [red]Archivo de video no encontrado: {video_path}[/red]")
        raise typer.Exit(1)
    
    output_path = Path(output_dir)
    
    try:
        with console.status("Transcribiendo con Whisper..."):
            result = transcribe_video_file(
                video_path=video_file,
                output_dir=output_path,
                model=model,
                device=device,
                language=language
            )
        
        if result["success"]:
            console.print("‚úÖ [green]Transcripci√≥n completada[/green]")
            console.print(f"   üìÑ JSON: {result['transcript_json']}")
            console.print(f"   üìù SRT: {result['transcript_srt']}")
            console.print(f"   üåç Idioma: {result['language']}")
            console.print(f"   ‚è±Ô∏è Duraci√≥n: {result['duration']:.1f}s")
            console.print(f"   üìä Segmentos: {result['segments_count']}")
            console.print(f"   üéØ Calidad: {result['quality_score']:.1f}/100")
        else:
            console.print("‚ùå [red]Error en transcripci√≥n[/red]")
            raise typer.Exit(1)
    
    except TranscriptionError as e:
        console.print(f"‚ùå [red]Error: {e}[/red]")
        raise typer.Exit(1)



@app.command()
def segment(
    transcript_path: str = typer.Argument(..., help="Ruta al archivo de transcripci√≥n"),
    output_dir: str = typer.Option("data/segments", help="Directorio de salida"),
    keywords: str = typer.Option("", help="Palabras clave separadas por comas"),
    min_duration: int = typer.Option(15, help="Duraci√≥n m√≠nima del clip (s)"),
    max_duration: int = typer.Option(59, help="Duraci√≥n m√°xima del clip (s)")
):
    """Segmentar transcripci√≥n en clips candidatos."""
    from pathlib import Path
    from .pipeline.segmenter import segment_transcript_file, SegmentationError
    
    console.print(f"‚úÇÔ∏è [bold]Segmentando transcripci√≥n:[/bold] {transcript_path}")
    
    transcript_file = Path(transcript_path)
    if not transcript_file.exists():
        console.print(f"‚ùå [red]Archivo de transcripci√≥n no encontrado: {transcript_path}[/red]")
        raise typer.Exit(1)
    
    output_path = Path(output_dir)
    
    # Preparar configuraci√≥n
    config = {
        "min_clip_duration": min_duration,
        "max_clip_duration": max_duration,
        "target_clip_duration": (min_duration + max_duration) // 2,
        "overlap_threshold": 0.1,
        "scoring_weights": {
            "keyword_match": 0.3,
            "sentence_completeness": 0.25,
            "duration_fit": 0.25,
            "speech_quality": 0.2
        },
        "important_keywords": []
    }
    
    # Procesar palabras clave
    keywords_list = None
    if keywords.strip():
        keywords_list = [k.strip().lower() for k in keywords.split(",") if k.strip()]
        console.print(f"üîç Filtrando por palabras clave: {', '.join(keywords_list)}")
    
    try:
        with console.status("Segmentando transcripci√≥n..."):
            candidates = segment_transcript_file(
                transcript_path=transcript_file,
                output_dir=output_path,
                config=config,
                keywords_filter=keywords_list
            )
        
        console.print("‚úÖ [green]Segmentaci√≥n completada[/green]")
        console.print(f"   üìä Clips candidatos: {len(candidates)}")
        
        if candidates:
            console.print("\nüèÜ [bold]Top 5 candidatos:[/bold]")
            for i, candidate in enumerate(candidates[:5], 1):
                console.print(
                    f"   {i}. {candidate.formatted_duration} | "
                    f"Score: {candidate.score:.1f} | "
                    f"{candidate.text[:60]}..."
                )
        
        export_path = output_path / f"{transcript_file.stem}_candidates.json"
        console.print(f"   üìÑ Candidatos exportados: {export_path}")
    
    except SegmentationError as e:
        console.print(f"‚ùå [red]Error: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def segment_ai(
    transcript_path: str = typer.Argument(..., help="Ruta al archivo de transcripci√≥n JSON"),
    output_dir: str = typer.Option("data/segments", help="Directorio de salida"),
    keywords: str = typer.Option("", help="Palabras clave separadas por comas"),
    max_clips: int = typer.Option(5, help="M√°ximo n√∫mero de clips a generar"),
    min_duration: int = typer.Option(15, help="Duraci√≥n m√≠nima del clip (s)"),
    max_duration: int = typer.Option(59, help="Duraci√≥n m√°xima del clip (s)")
):
    """ü§ñ Segmentar transcripci√≥n usando IA (ChatGPT)."""
    from pathlib import Path
    from .pipeline.ai_segmenter import AITranscriptSegmenter, AISegmentationConfig, SegmentationError
    import json
    
    console.print(f"ü§ñ [bold]Segmentando con IA:[/bold] {transcript_path}")
    
    transcript_file = Path(transcript_path)
    if not transcript_file.exists():
        console.print(f"‚ùå [red]Archivo de transcripci√≥n no encontrado: {transcript_path}[/red]")
        raise typer.Exit(1)
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Configurar segmentador IA
    config = AISegmentationConfig(
        max_clips=max_clips,
        min_duration=min_duration,
        max_duration=max_duration,
        target_duration=(min_duration + max_duration) / 2
    )
    
    # Procesar palabras clave
    keywords_list = None
    if keywords.strip():
        keywords_list = [k.strip().lower() for k in keywords.split(",") if k.strip()]
        console.print(f"üîç Palabras clave: {', '.join(keywords_list)}")
    
    try:
        segmenter = AITranscriptSegmenter(config)
        
        with console.status("Analizando con ChatGPT..."):
            candidates = segmenter.segment_transcript(
                transcript_file, 
                keywords_filter=keywords_list
            )
        
        console.print("‚úÖ [green]Segmentaci√≥n IA completada[/green]")
        console.print(f"   üìä Clips candidatos: {len(candidates)}")
        
        if candidates:
            console.print("\nüèÜ [bold]Top clips por IA:[/bold]")
            for i, candidate in enumerate(candidates[:5], 1):
                metadata = candidate.metadata
                title = metadata.get("title", "Sin t√≠tulo")
                viral_score = metadata.get("viral_potential", 0)
                content_type = metadata.get("content_type", "unknown")
                
                console.print(
                    f"   {i}. {candidate.formatted_duration} | "
                    f"Viral: {viral_score}/100 | "
                    f"Tipo: {content_type}"
                )
                console.print(f"      üìù {title}")
                console.print(f"      üéØ {candidate.text[:80]}...")
                console.print()
        
        # Exportar candidatos
        export_data = {
            "candidates": [],
            "metadata": {
                "generated_by": "AI",
                "model": config.model,
                "total_candidates": len(candidates),
                "generation_timestamp": str(Path().cwd())
            }
        }
        
        for candidate in candidates:
            export_data["candidates"].append({
                "id": candidate.id,
                "start_time": candidate.start_time,
                "end_time": candidate.end_time,
                "duration": candidate.duration,
                "text": candidate.text,
                "keywords": candidate.keywords,
                "score": candidate.score,
                "metadata": candidate.metadata
            })
        
        export_path = output_path / f"{transcript_file.stem}_ai_candidates.json"
        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        console.print(f"   üìÑ Candidatos IA exportados: {export_path}")
    
    except SegmentationError as e:
        console.print(f"‚ùå [red]Error: {e}[/red]")
        raise typer.Exit(1)
    except Exception as e:
        console.print(f"‚ùå [red]Error inesperado: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def pipeline_ai(
    podcast_video: str = typer.Argument(..., help="Ruta al video de podcast"),
    broll_video: str = typer.Argument(..., help="Ruta al video de B-roll"),
    keywords: str = typer.Option("", help="Palabras clave separadas por comas"),
    max_shorts: int = typer.Option(3, help="M√°ximo n√∫mero de Shorts a crear"),
    whisper_model: str = typer.Option("small", help="Modelo Whisper"),
    language: str = typer.Option("es", help="Idioma del podcast"),
    output_base: str = typer.Option("data", help="Directorio base de salida")
):
    """üöÄ Pipeline completo: transcribir ‚Üí segmentar con IA ‚Üí componer Shorts."""
    from pathlib import Path
    from .pipeline.transcribe import transcribe_video_file, TranscriptionError
    from .pipeline.ai_segmenter import AITranscriptSegmenter, AISegmentationConfig, SegmentationError
    from .pipeline.editor import compose_short_from_files, CompositionError
    import json
    
    console.print("üöÄ [bold]Iniciando pipeline completo con IA[/bold]")
    
    # Verificar archivos de entrada
    podcast_path = Path(podcast_video)
    broll_path = Path(broll_video)
    
    if not podcast_path.exists():
        console.print(f"‚ùå [red]Video de podcast no encontrado: {podcast_path}[/red]")
        raise typer.Exit(1)
    
    if not broll_path.exists():
        console.print(f"‚ùå [red]Video de B-roll no encontrado: {broll_path}[/red]")
        raise typer.Exit(1)
    
    base_name = podcast_path.stem
    base_dir = Path(output_base)
    
    # Configurar directorios
    transcripts_dir = base_dir / "transcripts"
    segments_dir = base_dir / "segments"  
    shorts_dir = base_dir / "shorts_ai"
    
    for dir_path in [transcripts_dir, segments_dir, shorts_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    try:
        # Paso 1: Transcribir
        console.print("\nüìù [bold cyan]Paso 1: Transcribiendo video...[/bold cyan]")
        transcript_path = transcripts_dir / f"{base_name}_transcript.json"
        
        if not transcript_path.exists():
            with console.status("Transcribiendo con Whisper..."):
                result = transcribe_video_file(
                    video_path=podcast_path,
                    output_dir=transcripts_dir,
                    model=whisper_model,
                    language=language,
                    device="cpu"
                )
            console.print(f"‚úÖ Transcripci√≥n completada: {result['json_path']}")
        else:
            console.print(f"‚úÖ Transcripci√≥n encontrada: {transcript_path}")
        
        # Paso 2: Segmentar con IA
        console.print("\nü§ñ [bold magenta]Paso 2: Segmentando con IA...[/bold magenta]")
        
        config = AISegmentationConfig(max_clips=max_shorts + 2)  # Pedir un poco m√°s
        segmenter = AITranscriptSegmenter(config)
        
        keywords_list = None
        if keywords.strip():
            keywords_list = [k.strip().lower() for k in keywords.split(",") if k.strip()]
            console.print(f"üîç Palabras clave: {', '.join(keywords_list)}")
        
        with console.status("Analizando contenido con ChatGPT..."):
            candidates = segmenter.segment_transcript(
                transcript_path,
                keywords_filter=keywords_list
            )
        
        console.print(f"‚úÖ IA encontr√≥ {len(candidates)} clips candidatos")
        
        # Exportar candidatos IA
        ai_candidates_path = segments_dir / f"{base_name}_ai_candidates.json"
        export_data = {
            "candidates": [
                {
                    "id": c.id,
                    "start_time": c.start_time,
                    "end_time": c.end_time,
                    "duration": c.duration,
                    "text": c.text,
                    "keywords": c.keywords,
                    "score": c.score,
                    "metadata": c.metadata
                } for c in candidates
            ],
            "metadata": {
                "generated_by": "AI",
                "model": config.model,
                "total_candidates": len(candidates)
            }
        }
        
        with open(ai_candidates_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        # Mostrar top clips
        if candidates:
            console.print("\nüèÜ [bold]Top clips seleccionados:[/bold]")
            for i, candidate in enumerate(candidates[:max_shorts], 1):
                metadata = candidate.metadata
                title = metadata.get("title", "Sin t√≠tulo")
                viral_score = metadata.get("viral_potential", 0)
                content_type = metadata.get("content_type", "unknown")
                
                console.print(
                    f"   {i}. {candidate.formatted_duration} | "
                    f"Viral: {viral_score}/100 | "
                    f"Tipo: {content_type}"
                )
                console.print(f"      üìù {title}")
        
        # Paso 3: Componer Shorts
        console.print(f"\nüé¨ [bold green]Paso 3: Componiendo {max_shorts} Shorts...[/bold green]")
        
        with console.status("Generando Shorts finales..."):
            results = compose_short_from_files(
                candidates_json=ai_candidates_path,
                podcast_video=podcast_path,
                broll_video=broll_path,
                transcript_json=transcript_path,
                output_dir=shorts_dir,
                max_shorts=max_shorts
            )
        
        # Resumen final
        successful_shorts = [r for r in results if r.get("success", False)]
        
        console.print(f"\nüéâ [bold green]Pipeline completo finalizado![/bold green]")
        console.print(f"   üìπ Shorts creados: {len(successful_shorts)}")
        console.print(f"   üìÅ Ubicaci√≥n: {shorts_dir}")
        
        if successful_shorts:
            console.print("\nüìä [bold]Shorts generados:[/bold]")
            for i, result in enumerate(successful_shorts, 1):
                file_path = result["output_path"]
                duration = result["duration"]
                file_size = result["file_size_mb"]
                console.print(f"   {i}. {file_path.name} ({duration:.1f}s, {file_size:.1f}MB)")
        
        console.print(f"\nüí° [yellow]Para ver los videos:[/yellow] xdg-open {shorts_dir}")
    
    except (TranscriptionError, SegmentationError, CompositionError) as e:
        console.print(f"‚ùå [red]Error en el pipeline: {e}[/red]")
        raise typer.Exit(1)
    except Exception as e:
        console.print(f"‚ùå [red]Error inesperado: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def compose(
    candidates_path: str = typer.Argument(..., help="Ruta al archivo de candidatos JSON"),
    podcast_video: str = typer.Argument(..., help="Ruta al video de podcast"),
    broll_video: str = typer.Argument(..., help="Ruta al video de B-roll"),
    transcript_path: str = typer.Argument(..., help="Ruta al archivo de transcripci√≥n JSON"),
    output_dir: str = typer.Option("data/shorts", help="Directorio de salida"),
    max_shorts: int = typer.Option(3, help="M√°ximo n√∫mero de Shorts a crear"),
    no_subtitles: bool = typer.Option(False, help="No incluir subt√≠tulos quemados")
):
    """Componer Shorts finales con layout dual-panel."""
    from pathlib import Path
    from .pipeline.editor import compose_short_from_files, CompositionError
    
    console.print(f"üé¨ [bold]Componiendo Shorts:[/bold] {max_shorts} shorts m√°ximo")
    
    # Verificar archivos de entrada
    files_to_check = {
        "Candidatos": Path(candidates_path),
        "Video podcast": Path(podcast_video), 
        "Video B-roll": Path(broll_video),
        "Transcripci√≥n": Path(transcript_path)
    }
    
    for name, file_path in files_to_check.items():
        if not file_path.exists():
            console.print(f"‚ùå [red]{name} no encontrado: {file_path}[/red]")
            raise typer.Exit(1)
    
    output_path = Path(output_dir)
    
    try:
        with console.status("Componiendo Shorts..."):
            results = compose_short_from_files(
                podcast_video=Path(podcast_video),
                broll_video=Path(broll_video),
                transcript_json=Path(transcript_path),
                candidates_json=Path(candidates_path),
                output_dir=output_path,
                max_shorts=max_shorts
            )
        
        # Mostrar resultados
        successful = [r for r in results if r.get("success", False)]
        failed = [r for r in results if not r.get("success", False)]
        
        console.print("‚úÖ [green]Composici√≥n completada[/green]")
        console.print(f"   üìπ Shorts creados: {len(successful)}")
        console.print(f"   ‚ùå Errores: {len(failed)}")
        
        if successful:
            console.print("\nüéØ [bold]Shorts creados exitosamente:[/bold]")
            for i, result in enumerate(successful, 1):
                duration = result.get("duration", 0)
                file_size_mb = result.get("file_size", 0) / (1024 * 1024)
                console.print(
                    f"   {i}. {Path(result['output_path']).name} "
                    f"({duration:.1f}s, {file_size_mb:.1f}MB)"
                )
        
        if failed:
            console.print("\n‚ùå [bold]Errores en composici√≥n:[/bold]")
            for result in failed:
                console.print(f"   ‚Ä¢ {result['candidate_id']}: {result.get('error', 'Error desconocido')}")
        
        console.print(f"\nüìÅ Archivos guardados en: {output_path}")
    
    except CompositionError as e:
        console.print(f"‚ùå [red]Error en composici√≥n: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def publish(
    limit: Annotated[int, typer.Option("--limit", help="L√≠mite de publicaciones")] = 1,
    schedule: Annotated[bool, typer.Option("--schedule", help="Programar publicaci√≥n")] = False,
    dry_run: Annotated[bool, typer.Option("--dry-run", help="Simular sin publicar")] = False,
):
    """üì§ Publicar Shorts en YouTube usando API oficial."""
    rprint("[yellow]üì§ Publicando en YouTube...[/yellow]")
    
    # TODO: Implementar publisher.py
    rprint(f"[blue]üìä L√≠mite:[/blue] {limit}")
    rprint(f"[blue]‚è∞ Programar:[/blue] {schedule}")
    rprint(f"[blue]üîç Dry run:[/blue] {dry_run}")
    rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")


@app.command()
def autopipeline(
    max_videos: Annotated[int, typer.Option(help="M√°x videos a procesar en este ciclo")] = 1,
    max_shorts: Annotated[int, typer.Option(help="M√°x shorts por video")] = 3,
    db_path: Annotated[Path, typer.Option(help="Ruta DB")] = Path("data/pipeline.db"),
    workdir: Annotated[Path, typer.Option(help="Directorio trabajo")] = Path("data"),
    whisper_model: Annotated[str, typer.Option(help="Modelo Whisper")] = "base",
    language: Annotated[str, typer.Option(help="Idioma forzado",)] = None,
):
    """ü§ñ Ejecuta discover‚Üídownload‚Üítranscribe‚Üísegment‚Üícompose secuencial para nuevos videos."""
    from .pipeline.autopipeline import run_autopipeline
    rprint("[yellow]ü§ñ Ejecutando autopipeline...[/yellow]")
    results = run_autopipeline(
        db_path=db_path,
        workdir=workdir,
        max_videos=max_videos,
        max_shorts_per_video=max_shorts,
        whisper_model=whisper_model,
        language=language,
    )
    if not results:
        rprint("[cyan]‚ÑπÔ∏è  Nada que procesar[/cyan]")
        return
    for r in results:
        if r['success']:
            rprint(f"[green]‚úÖ {r['video_id']} -> shorts: {r.get('shorts_generated',0)}[/green]")
        else:
            rprint(f"[red]‚ùå {r['video_id']} {r.get('error')}")


@app.command()
def status():
    """üìä Mostrar estado actual del pipeline."""
    from .pipeline.db import PipelineDB
    db_path = Path("data/pipeline.db")
    if db_path.exists():
        db = PipelineDB(str(db_path))
        stats = db.get_stats()
        body = (
            "[bold blue]üìä Estado del Pipeline[/bold blue]\n\n"
            f"[dim]üîç Videos descubiertos:[/dim] {stats['total_videos']}\n"
            f"[dim]‚¨áÔ∏è  Videos descargados:[/dim] {stats['downloaded']}\n"
            f"[dim]‚úÇÔ∏è  Clips generados:[/dim] {stats['segments']}\n"
            f"[dim]üé¨ Shorts compuestos:[/dim] {stats['composites']}\n"
            f"[dim]üì§ Publicados:[/dim] {stats['uploaded']}\n"
        )
    else:
        body = (
            "[bold blue]üìä Estado del Pipeline[/bold blue]\n\n"
            "[yellow]‚ö†Ô∏è  Base de datos no inicializada[/yellow]"
        )
    rprint(Panel.fit(body, title="Estado"))


@app.command()
def config(
    show: Annotated[bool, typer.Option("--show", help="Mostrar configuraci√≥n actual")] = False,
    validate: Annotated[bool, typer.Option("--validate", help="Validar configuraci√≥n")] = False,
):
    """‚öôÔ∏è Gestionar configuraci√≥n del pipeline."""
    if show:
        rprint("[blue]üìã Configuraci√≥n actual:[/blue]")
        # TODO: Leer y mostrar configuraci√≥n de .env y configs/
        rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")
    
    if validate:
        rprint("[blue]‚úÖ Validando configuraci√≥n...[/blue]")
        # TODO: Validar archivos de configuraci√≥n
        rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")


@app.command()
def doctor():
    """ü©∫ Diagnosticar problemas del sistema."""
    rprint("[yellow]ü©∫ Ejecutando diagn√≥sticos...[/yellow]")
    
    # Verificar Python
    python_version = sys.version_info
    if python_version >= (3, 11):
        rprint("[green]‚úÖ Python 3.11+ detectado[/green]")
    else:
        rprint("[red]‚ùå Se requiere Python 3.11+[/red]")
    
    # Verificar estructura de carpetas
    data_dir = Path("data")
    if data_dir.exists():
        rprint("[green]‚úÖ Estructura de carpetas creada[/green]")
    else:
        rprint("[red]‚ùå Falta estructura de carpetas (ejecuta 'make setup')[/red]")
    
    # Verificar .env
    env_file = Path(".env")
    if env_file.exists():
        rprint("[green]‚úÖ Archivo .env encontrado[/green]")
    else:
        rprint("[yellow]‚ö†Ô∏è  Archivo .env no encontrado (copia .env.example)[/yellow]")
    
    rprint("[blue]üí° Para m√°s diagn√≥sticos, ejecuta 'make doctor'[/blue]")


if __name__ == "__main__":
    app()
