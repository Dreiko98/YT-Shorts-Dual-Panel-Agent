#!/usr/bin/env python3
"""
CLI principal para el pipeline de YT Shorts Dual-Panel Agent.
"""

import sys
from pathlib import Path
from typing import Optional

import typer
from rich import print as rprint
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress
from typing_extensions import Annotated

# A√±adir src/ al path para imports
sys.path.insert(0, str(Path(__file__).parent))

app = typer.Typer(
    name="yts",
    help="üé¨ YT Shorts Dual-Panel Agent - Pipeline automatizado para generar YouTube Shorts",
    rich_markup_mode="rich",
)
console = Console()


@app.command()
def discover(
    channel_ids: Annotated[
        Optional[str], 
        typer.Option("--channels", "-c", help="IDs de canales separados por coma")
    ] = None,
    max_videos: Annotated[
        int, 
        typer.Option("--max", "-m", help="M√°ximo n√∫mero de v√≠deos a descubrir")
    ] = 50,
    verbose: Annotated[bool, typer.Option("--verbose", "-v")] = False,
):
    """üîç Descubrir nuevos episodios de podcast usando YouTube Data API."""
    rprint("[yellow]üîç Descubriendo nuevos episodios...[/yellow]")
    
    if not channel_ids:
        rprint("[red]‚ùå No se especificaron canales. Usa --channels o configura channels.yaml[/red]")
        raise typer.Exit(1)
    
    # TODO: Implementar discovery.py
    rprint("[blue]üìã Canales a procesar:[/blue]", channel_ids)
    rprint(f"[blue]üìä L√≠mite de v√≠deos:[/blue] {max_videos}")
    rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")


@app.command()
def download(
    limit: Annotated[
        int, 
        typer.Option("--limit", "-l", help="L√≠mite de descargas simult√°neas")
    ] = 3,
    quality: Annotated[
        str, 
        typer.Option("--quality", "-q", help="Calidad de descarga")
    ] = "best[height<=1080]",
    verbose: Annotated[bool, typer.Option("--verbose", "-v")] = False,
):
    """‚¨áÔ∏è  Descargar podcasts pendientes usando yt-dlp."""
    rprint("[yellow]‚¨áÔ∏è  Descargando podcasts pendientes...[/yellow]")
    
    # TODO: Implementar downloader.py
    rprint(f"[blue]üìä L√≠mite simult√°neo:[/blue] {limit}")
    rprint(f"[blue]üé• Calidad:[/blue] {quality}")
    rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")


@app.command()
def normalize(
    force: Annotated[bool, typer.Option("--force", "-f", help="Forzar renormalizaci√≥n")] = False,
    target_fps: Annotated[int, typer.Option("--fps", help="FPS objetivo")] = 30,
):
    """üéµ Normalizar audio y video (fps, resoluci√≥n, loudness)."""
    rprint("[yellow]üéµ Normalizando audio/video...[/yellow]")
    
    # TODO: Implementar normalize.py
    rprint(f"[blue]üéØ FPS objetivo:[/blue] {target_fps}")
    rprint(f"[blue]üîÑ Forzar renormalizaci√≥n:[/blue] {force}")
    rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")


@app.command()
def transcribe(
    video_path: str = typer.Argument(..., help="Ruta al archivo de video"),
    output_dir: str = typer.Option("data/transcripts", help="Directorio de salida"),
    model: str = typer.Option("base", help="Modelo Whisper (tiny, base, small, medium, large)"),
    language: str = typer.Option(None, help="Idioma forzado (es, en, etc.)"),
    device: str = typer.Option("auto", help="Dispositivo (auto, cpu, cuda)")
):
    """Transcribir video usando Whisper."""
    from pathlib import Path
    from .pipeline.transcribe import transcribe_video_file, TranscriptionError, check_whisper_requirements
    
    console.print(f"üé§ [bold]Transcribiendo video:[/bold] {video_path}")
    
    # Verificar requirements
    requirements = check_whisper_requirements()
    if not requirements["whisper_installed"]:
        console.print("‚ùå [red]Whisper no est√° instalado. Ejecuta: pip install openai-whisper[/red]")
        raise typer.Exit(1)
    
    if not requirements["torch_available"]:
        console.print("‚ùå [red]PyTorch no est√° disponible[/red]")
        raise typer.Exit(1)
    
    video_file = Path(video_path)
    if not video_file.exists():
        console.print(f"‚ùå [red]Archivo de video no encontrado: {video_path}[/red]")
        raise typer.Exit(1)
    
    output_path = Path(output_dir)
    
    try:
        with console.status("Transcribiendo con Whisper..."):
            result = transcribe_video_file(
                video_path=video_file,
                output_dir=output_path,
                model=model,
                device=device,
                language=language
            )
        
        if result["success"]:
            console.print("‚úÖ [green]Transcripci√≥n completada[/green]")
            console.print(f"   üìÑ JSON: {result['transcript_json']}")
            console.print(f"   üìù SRT: {result['transcript_srt']}")
            console.print(f"   üåç Idioma: {result['language']}")
            console.print(f"   ‚è±Ô∏è Duraci√≥n: {result['duration']:.1f}s")
            console.print(f"   üìä Segmentos: {result['segments_count']}")
            console.print(f"   üéØ Calidad: {result['quality_score']:.1f}/100")
        else:
            console.print("‚ùå [red]Error en transcripci√≥n[/red]")
            raise typer.Exit(1)
    
    except TranscriptionError as e:
        console.print(f"‚ùå [red]Error: {e}[/red]")
        raise typer.Exit(1)



@app.command()
def segment(
    transcript_path: str = typer.Argument(..., help="Ruta al archivo de transcripci√≥n"),
    output_dir: str = typer.Option("data/segments", help="Directorio de salida"),
    keywords: str = typer.Option("", help="Palabras clave separadas por comas"),
    min_duration: int = typer.Option(15, help="Duraci√≥n m√≠nima del clip (s)"),
    max_duration: int = typer.Option(59, help="Duraci√≥n m√°xima del clip (s)")
):
    """Segmentar transcripci√≥n en clips candidatos."""
    from pathlib import Path
    from .pipeline.segmenter import segment_transcript_file, SegmentationError
    
    console.print(f"‚úÇÔ∏è [bold]Segmentando transcripci√≥n:[/bold] {transcript_path}")
    
    transcript_file = Path(transcript_path)
    if not transcript_file.exists():
        console.print(f"‚ùå [red]Archivo de transcripci√≥n no encontrado: {transcript_path}[/red]")
        raise typer.Exit(1)
    
    output_path = Path(output_dir)
    
    # Preparar configuraci√≥n
    config = {
        "min_clip_duration": min_duration,
        "max_clip_duration": max_duration,
        "target_clip_duration": (min_duration + max_duration) // 2,
        "overlap_threshold": 0.1,
        "scoring_weights": {
            "keyword_match": 0.3,
            "sentence_completeness": 0.25,
            "duration_fit": 0.25,
            "speech_quality": 0.2
        },
        "important_keywords": []
    }
    
    # Procesar palabras clave
    keywords_list = None
    if keywords.strip():
        keywords_list = [k.strip().lower() for k in keywords.split(",") if k.strip()]
        console.print(f"üîç Filtrando por palabras clave: {', '.join(keywords_list)}")
    
    try:
        with console.status("Segmentando transcripci√≥n..."):
            candidates = segment_transcript_file(
                transcript_path=transcript_file,
                output_dir=output_path,
                config=config,
                keywords_filter=keywords_list
            )
        
        console.print("‚úÖ [green]Segmentaci√≥n completada[/green]")
        console.print(f"   üìä Clips candidatos: {len(candidates)}")
        
        if candidates:
            console.print("\nüèÜ [bold]Top 5 candidatos:[/bold]")
            for i, candidate in enumerate(candidates[:5], 1):
                console.print(
                    f"   {i}. {candidate.formatted_duration} | "
                    f"Score: {candidate.score:.1f} | "
                    f"{candidate.text[:60]}..."
                )
        
        export_path = output_path / f"{transcript_file.stem}_candidates.json"
        console.print(f"   üìÑ Candidatos exportados: {export_path}")
    
    except SegmentationError as e:
        console.print(f"‚ùå [red]Error: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def segment_ai(
    transcript_path: str = typer.Argument(..., help="Ruta al archivo de transcripci√≥n JSON"),
    output_dir: str = typer.Option("data/segments", help="Directorio de salida"),
    keywords: str = typer.Option("", help="Palabras clave separadas por comas"),
    max_clips: int = typer.Option(5, help="M√°ximo n√∫mero de clips a generar"),
    min_duration: int = typer.Option(15, help="Duraci√≥n m√≠nima del clip (s)"),
    max_duration: int = typer.Option(59, help="Duraci√≥n m√°xima del clip (s)")
):
    """ü§ñ Segmentar transcripci√≥n usando IA (ChatGPT)."""
    from pathlib import Path
    from .pipeline.ai_segmenter import AITranscriptSegmenter, AISegmentationConfig, SegmentationError
    import json
    
    console.print(f"ü§ñ [bold]Segmentando con IA:[/bold] {transcript_path}")
    
    transcript_file = Path(transcript_path)
    if not transcript_file.exists():
        console.print(f"‚ùå [red]Archivo de transcripci√≥n no encontrado: {transcript_path}[/red]")
        raise typer.Exit(1)
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Configurar segmentador IA
    config = AISegmentationConfig(
        max_clips=max_clips,
        min_duration=min_duration,
        max_duration=max_duration,
        target_duration=(min_duration + max_duration) / 2
    )
    
    # Procesar palabras clave
    keywords_list = None
    if keywords.strip():
        keywords_list = [k.strip().lower() for k in keywords.split(",") if k.strip()]
        console.print(f"üîç Palabras clave: {', '.join(keywords_list)}")
    
    try:
        segmenter = AITranscriptSegmenter(config)
        
        with console.status("Analizando con ChatGPT..."):
            candidates = segmenter.segment_transcript(
                transcript_file, 
                keywords_filter=keywords_list
            )
        
        console.print("‚úÖ [green]Segmentaci√≥n IA completada[/green]")
        console.print(f"   üìä Clips candidatos: {len(candidates)}")
        
        if candidates:
            console.print("\nüèÜ [bold]Top clips por IA:[/bold]")
            for i, candidate in enumerate(candidates[:5], 1):
                metadata = candidate.metadata
                title = metadata.get("title", "Sin t√≠tulo")
                viral_score = metadata.get("viral_potential", 0)
                content_type = metadata.get("content_type", "unknown")
                
                console.print(
                    f"   {i}. {candidate.formatted_duration} | "
                    f"Viral: {viral_score}/100 | "
                    f"Tipo: {content_type}"
                )
                console.print(f"      üìù {title}")
                console.print(f"      üéØ {candidate.text[:80]}...")
                console.print()
        
        # Exportar candidatos
        export_data = {
            "candidates": [],
            "metadata": {
                "generated_by": "AI",
                "model": config.model,
                "total_candidates": len(candidates),
                "generation_timestamp": str(Path().cwd())
            }
        }
        
        for candidate in candidates:
            export_data["candidates"].append({
                "id": candidate.id,
                "start_time": candidate.start_time,
                "end_time": candidate.end_time,
                "duration": candidate.duration,
                "text": candidate.text,
                "keywords": candidate.keywords,
                "score": candidate.score,
                "metadata": candidate.metadata
            })
        
        export_path = output_path / f"{transcript_file.stem}_ai_candidates.json"
        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        console.print(f"   üìÑ Candidatos IA exportados: {export_path}")
    
    except SegmentationError as e:
        console.print(f"‚ùå [red]Error: {e}[/red]")
        raise typer.Exit(1)
    except Exception as e:
        console.print(f"‚ùå [red]Error inesperado: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def pipeline_ai(
    podcast_video: str = typer.Argument(..., help="Ruta al video de podcast"),
    broll_video: str = typer.Argument(..., help="Ruta al video de B-roll"),
    keywords: str = typer.Option("", help="Palabras clave separadas por comas"),
    max_shorts: int = typer.Option(3, help="M√°ximo n√∫mero de Shorts a crear"),
    whisper_model: str = typer.Option("small", help="Modelo Whisper"),
    language: str = typer.Option("es", help="Idioma del podcast"),
    output_base: str = typer.Option("data", help="Directorio base de salida")
):
    """üöÄ Pipeline completo: transcribir ‚Üí segmentar con IA ‚Üí componer Shorts."""
    from pathlib import Path
    from .pipeline.transcribe import transcribe_video_file, TranscriptionError
    from .pipeline.ai_segmenter import AITranscriptSegmenter, AISegmentationConfig, SegmentationError
    from .pipeline.editor import compose_short_from_files, CompositionError
    import json
    
    console.print("üöÄ [bold]Iniciando pipeline completo con IA[/bold]")
    
    # Verificar archivos de entrada
    podcast_path = Path(podcast_video)
    broll_path = Path(broll_video)
    
    if not podcast_path.exists():
        console.print(f"‚ùå [red]Video de podcast no encontrado: {podcast_path}[/red]")
        raise typer.Exit(1)
    
    if not broll_path.exists():
        console.print(f"‚ùå [red]Video de B-roll no encontrado: {broll_path}[/red]")
        raise typer.Exit(1)
    
    base_name = podcast_path.stem
    base_dir = Path(output_base)
    
    # Configurar directorios
    transcripts_dir = base_dir / "transcripts"
    segments_dir = base_dir / "segments"  
    shorts_dir = base_dir / "shorts_ai"
    
    for dir_path in [transcripts_dir, segments_dir, shorts_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    try:
        # Paso 1: Transcribir
        console.print("\nüìù [bold cyan]Paso 1: Transcribiendo video...[/bold cyan]")
        transcript_path = transcripts_dir / f"{base_name}_transcript.json"
        
        if not transcript_path.exists():
            with console.status("Transcribiendo con Whisper..."):
                result = transcribe_video_file(
                    video_path=podcast_path,
                    output_dir=transcripts_dir,
                    model=whisper_model,
                    language=language,
                    device="cpu"
                )
            console.print(f"‚úÖ Transcripci√≥n completada: {result['json_path']}")
        else:
            console.print(f"‚úÖ Transcripci√≥n encontrada: {transcript_path}")
        
        # Paso 2: Segmentar con IA
        console.print("\nü§ñ [bold magenta]Paso 2: Segmentando con IA...[/bold magenta]")
        
        config = AISegmentationConfig(max_clips=max_shorts + 2)  # Pedir un poco m√°s
        segmenter = AITranscriptSegmenter(config)
        
        keywords_list = None
        if keywords.strip():
            keywords_list = [k.strip().lower() for k in keywords.split(",") if k.strip()]
            console.print(f"üîç Palabras clave: {', '.join(keywords_list)}")
        
        with console.status("Analizando contenido con ChatGPT..."):
            candidates = segmenter.segment_transcript(
                transcript_path,
                keywords_filter=keywords_list
            )
        
        console.print(f"‚úÖ IA encontr√≥ {len(candidates)} clips candidatos")
        
        # Exportar candidatos IA
        ai_candidates_path = segments_dir / f"{base_name}_ai_candidates.json"
        export_data = {
            "candidates": [
                {
                    "id": c.id,
                    "start_time": c.start_time,
                    "end_time": c.end_time,
                    "duration": c.duration,
                    "text": c.text,
                    "keywords": c.keywords,
                    "score": c.score,
                    "metadata": c.metadata
                } for c in candidates
            ],
            "metadata": {
                "generated_by": "AI",
                "model": config.model,
                "total_candidates": len(candidates)
            }
        }
        
        with open(ai_candidates_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        # Mostrar top clips
        if candidates:
            console.print("\nüèÜ [bold]Top clips seleccionados:[/bold]")
            for i, candidate in enumerate(candidates[:max_shorts], 1):
                metadata = candidate.metadata
                title = metadata.get("title", "Sin t√≠tulo")
                viral_score = metadata.get("viral_potential", 0)
                content_type = metadata.get("content_type", "unknown")
                
                console.print(
                    f"   {i}. {candidate.formatted_duration} | "
                    f"Viral: {viral_score}/100 | "
                    f"Tipo: {content_type}"
                )
                console.print(f"      üìù {title}")
        
        # Paso 3: Componer Shorts
        console.print(f"\nüé¨ [bold green]Paso 3: Componiendo {max_shorts} Shorts...[/bold green]")
        
        with console.status("Generando Shorts finales..."):
            results = compose_short_from_files(
                candidates_json=ai_candidates_path,
                podcast_video=podcast_path,
                broll_video=broll_path,
                transcript_json=transcript_path,
                output_dir=shorts_dir,
                max_shorts=max_shorts
            )
        
        # Resumen final
        successful_shorts = [r for r in results if r.get("success", False)]
        
        console.print(f"\nüéâ [bold green]Pipeline completo finalizado![/bold green]")
        console.print(f"   üìπ Shorts creados: {len(successful_shorts)}")
        console.print(f"   üìÅ Ubicaci√≥n: {shorts_dir}")
        
        if successful_shorts:
            console.print("\nüìä [bold]Shorts generados:[/bold]")
            for i, result in enumerate(successful_shorts, 1):
                file_path = result["output_path"]
                duration = result["duration"]
                file_size = result["file_size_mb"]
                console.print(f"   {i}. {file_path.name} ({duration:.1f}s, {file_size:.1f}MB)")
        
        console.print(f"\nüí° [yellow]Para ver los videos:[/yellow] xdg-open {shorts_dir}")
    
    except (TranscriptionError, SegmentationError, CompositionError) as e:
        console.print(f"‚ùå [red]Error en el pipeline: {e}[/red]")
        raise typer.Exit(1)
    except Exception as e:
        console.print(f"‚ùå [red]Error inesperado: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def compose(
    candidates_path: str = typer.Argument(..., help="Ruta al archivo de candidatos JSON"),
    podcast_video: str = typer.Argument(..., help="Ruta al video de podcast"),
    broll_video: str = typer.Argument(..., help="Ruta al video de B-roll"),
    transcript_path: str = typer.Argument(..., help="Ruta al archivo de transcripci√≥n JSON"),
    output_dir: str = typer.Option("data/shorts", help="Directorio de salida"),
    max_shorts: int = typer.Option(3, help="M√°ximo n√∫mero de Shorts a crear"),
    no_subtitles: bool = typer.Option(False, help="No incluir subt√≠tulos quemados")
):
    """Componer Shorts finales con layout dual-panel."""
    from pathlib import Path
    from .pipeline.editor import compose_short_from_files, CompositionError
    
    console.print(f"üé¨ [bold]Componiendo Shorts:[/bold] {max_shorts} shorts m√°ximo")
    
    # Verificar archivos de entrada
    files_to_check = {
        "Candidatos": Path(candidates_path),
        "Video podcast": Path(podcast_video), 
        "Video B-roll": Path(broll_video),
        "Transcripci√≥n": Path(transcript_path)
    }
    
    for name, file_path in files_to_check.items():
        if not file_path.exists():
            console.print(f"‚ùå [red]{name} no encontrado: {file_path}[/red]")
            raise typer.Exit(1)
    
    output_path = Path(output_dir)
    
    try:
        with console.status("Componiendo Shorts..."):
            results = compose_short_from_files(
                podcast_video=Path(podcast_video),
                broll_video=Path(broll_video),
                transcript_json=Path(transcript_path),
                candidates_json=Path(candidates_path),
                output_dir=output_path,
                max_shorts=max_shorts
            )
        
        # Mostrar resultados
        successful = [r for r in results if r.get("success", False)]
        failed = [r for r in results if not r.get("success", False)]
        
        console.print("‚úÖ [green]Composici√≥n completada[/green]")
        console.print(f"   üìπ Shorts creados: {len(successful)}")
        console.print(f"   ‚ùå Errores: {len(failed)}")
        
        if successful:
            console.print("\nüéØ [bold]Shorts creados exitosamente:[/bold]")
            for i, result in enumerate(successful, 1):
                duration = result.get("duration", 0)
                file_size_mb = result.get("file_size", 0) / (1024 * 1024)
                console.print(
                    f"   {i}. {Path(result['output_path']).name} "
                    f"({duration:.1f}s, {file_size_mb:.1f}MB)"
                )
        
        if failed:
            console.print("\n‚ùå [bold]Errores en composici√≥n:[/bold]")
            for result in failed:
                console.print(f"   ‚Ä¢ {result['candidate_id']}: {result.get('error', 'Error desconocido')}")
        
        console.print(f"\nüìÅ Archivos guardados en: {output_path}")
    
    except CompositionError as e:
        console.print(f"‚ùå [red]Error en composici√≥n: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def publish(
    limit: Annotated[int, typer.Option("--limit", help="L√≠mite de publicaciones")] = 1,
    schedule: Annotated[bool, typer.Option("--schedule", help="Programar publicaci√≥n")] = False,
    dry_run: Annotated[bool, typer.Option("--dry-run", help="Simular sin publicar")] = False,
):
    """üì§ Publicar Shorts en YouTube usando API oficial."""
    rprint("[yellow]üì§ Publicando en YouTube...[/yellow]")
    
    # TODO: Implementar publisher.py
    rprint(f"[blue]üìä L√≠mite:[/blue] {limit}")
    rprint(f"[blue]‚è∞ Programar:[/blue] {schedule}")
    rprint(f"[blue]üîç Dry run:[/blue] {dry_run}")
    rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")


@app.command()
def status():
    """üìä Mostrar estado actual del pipeline."""
    rprint(Panel.fit(
        "[bold blue]üìä Estado del Pipeline[/bold blue]\n\n"
        "[dim]üîç Videos descubiertos:[/dim] 0\n"
        "[dim]‚¨áÔ∏è  Videos descargados:[/dim] 0\n"
        "[dim]üìù Transcripciones:[/dim] 0\n"
        "[dim]‚úÇÔ∏è  Clips generados:[/dim] 0\n"
        "[dim]üé¨ Shorts compuestos:[/dim] 0\n"
        "[dim]üì§ Publicados:[/dim] 0\n\n"
        "[yellow]‚ö†Ô∏è  Base de datos no inicializada[/yellow]",
        title="Estado",
    ))


@app.command()
def config(
    show: Annotated[bool, typer.Option("--show", help="Mostrar configuraci√≥n actual")] = False,
    validate: Annotated[bool, typer.Option("--validate", help="Validar configuraci√≥n")] = False,
):
    """‚öôÔ∏è Gestionar configuraci√≥n del pipeline."""
    if show:
        rprint("[blue]üìã Configuraci√≥n actual:[/blue]")
        # TODO: Leer y mostrar configuraci√≥n de .env y configs/
        rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")
    
    if validate:
        rprint("[blue]‚úÖ Validando configuraci√≥n...[/blue]")
        # TODO: Validar archivos de configuraci√≥n
        rprint("[yellow]‚ö†Ô∏è  Funcionalidad pendiente de implementar[/yellow]")


@app.command()
def doctor():
    """ü©∫ Diagnosticar problemas del sistema."""
    rprint("[yellow]ü©∫ Ejecutando diagn√≥sticos...[/yellow]")
    
    # Verificar Python
    python_version = sys.version_info
    if python_version >= (3, 11):
        rprint("[green]‚úÖ Python 3.11+ detectado[/green]")
    else:
        rprint("[red]‚ùå Se requiere Python 3.11+[/red]")
    
    # Verificar estructura de carpetas
    data_dir = Path("data")
    if data_dir.exists():
        rprint("[green]‚úÖ Estructura de carpetas creada[/green]")
    else:
        rprint("[red]‚ùå Falta estructura de carpetas (ejecuta 'make setup')[/red]")
    
    # Verificar .env
    env_file = Path(".env")
    if env_file.exists():
        rprint("[green]‚úÖ Archivo .env encontrado[/green]")
    else:
        rprint("[yellow]‚ö†Ô∏è  Archivo .env no encontrado (copia .env.example)[/yellow]")
    
    rprint("[blue]üí° Para m√°s diagn√≥sticos, ejecuta 'make doctor'[/blue]")


if __name__ == "__main__":
    app()
